{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "from fastai import datasets\n",
    "import pickle,gzip,math,torch,matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    mnist_url='http://deeplearning.net/data/mnist/mnist.pkl'\n",
    "    path = datasets.download_data(mnist_url,ext='.gz')\n",
    "    with gzip.open(path,'rb') as f:\n",
    "        ((x_train, y_train), (x_valid,y_valid), _) = pickle.load(f,encoding='latin-1')\n",
    "    return map(tensor,(x_train,y_train,x_valid,y_valid))\n",
    "def normalize(x,m,s):\n",
    "    return (x-m)/s\n",
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n,features = x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = y_train.max()+1\n",
    "dims = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.float()\n",
    "y_valid = y_valid.float()\n",
    "m,s = x_train.mean(),x_train.std()\n",
    "x_train = normalize(x_train,m,s)\n",
    "x_valid = normalize(x_valid,m,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Red(nn.Module):\n",
    "    def __init__(self,n_in,dims,n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in,dims)\n",
    "        self.l2 = nn.Linear(dims,n_out)\n",
    "    def __call__(self,x):        \n",
    "        return self.l2(F.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RedSeq(nn.Module):\n",
    "    def __init__(self,layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "                \n",
    "    def __call__(self,x):        \n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = Red(features,dims,10)\n",
    "model = RedSeq([nn.Linear(features,dims),nn.ReLU(),nn.Linear(dims,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred=model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logsoftmax(x):\n",
    "    #esto es por error numerico\n",
    "    #  logexpsum\n",
    "    #  m = x.max(-1)[0]    \n",
    "    #  (m+(x-m[:,None]).exp().sum(-1).log())\n",
    "    return x - x.logsumexp(-1,keepdim=True)\n",
    "def nll(y_hat,y):\n",
    "    return -y_hat[range(y.shape[0]),y].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1056, -2.4495, -2.4392, -2.2497, -2.4000, -2.3233, -2.3163, -2.1620,\n",
       "         -2.1882, -2.4685],\n",
       "        [-2.2382, -2.3539, -2.4643, -2.2742, -2.3988, -2.2482, -2.3904, -2.1071,\n",
       "         -2.2030, -2.4043],\n",
       "        [-2.2220, -2.4391, -2.3489, -2.3275, -2.3357, -2.3011, -2.3410, -2.1813,\n",
       "         -2.1786, -2.3844],\n",
       "        [-2.2088, -2.4186, -2.3962, -2.2894, -2.4180, -2.2605, -2.3571, -2.1416,\n",
       "         -2.2086, -2.3718],\n",
       "        [-2.2101, -2.3163, -2.3080, -2.3713, -2.4250, -2.3472, -2.3855, -2.0497,\n",
       "         -2.2597, -2.4130]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logsoftmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYTORCH TIENE F.nnl_loss y F.log_softmax que forman\n",
    "# F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y_hat,y):\n",
    "    return (torch.argmax(y_hat,dim=1) == y).float().mean()\n",
    "loss_f = F.cross_entropy\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ -6.3996,   5.6154,  -1.2964,  24.1664, -31.0383,  32.2412, -17.6279,\n",
       "          -5.9492, -10.5892,   6.4689], grad_fn=<SelectBackward>),\n",
       " torch.Size([64, 10]))"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb = x_train[0:bs]\n",
    "preds = model(xb)\n",
    "preds[0],preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0046, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "loss_f(preds,yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds,yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self,params,lr = 0.5):\n",
    "        self.params,self.lr = list(params),lr\n",
    "        \n",
    "    def step(self):\n",
    "        #no calcules derivadas!\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                p-=p.grad * lr\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = .5\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0,x_train.shape[0],bs):\n",
    "        xb = x_train[i:i+bs]\n",
    "        preds = model(xb)\n",
    "        \n",
    "        yb = y_train[i:i+bs]                \n",
    "        loss = loss_f(preds,yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        opt.zero_grad()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds,yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 3, 7, 0, 9, 0, 8, 5, 5, 2, 4, 5, 0, 8, 4, 8])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(preds,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 3, 7, 0, 9, 0, 8, 5, 5, 2, 4, 5, 0, 8, 4, 8])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
